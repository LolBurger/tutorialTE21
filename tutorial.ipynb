{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Data preprocessing </center></h1>\n",
    "\n",
    "First we import the modules (libraries) required by the code. <br>\n",
    "Three modules are here included:\n",
    "- numpy: basic library for array handling and manipulation\n",
    "- pandas: library to handle I/O of files and data structure manipulation\n",
    "- matplotlib: data visualization\n",
    "\n",
    "<p>To increase the code readability, a common approach involves\n",
    "using aliases *(e.g. import pandas as <ins>pd</ins>)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Import the necessary modules and address them using aliases\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, we read the training database that was previously stored in\n",
    "a *Comma Separated Values* file *(.csv)*. <br>\n",
    "The input format strongly depends on the source that generated\n",
    "your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Read the training data stored in .csv file\n",
    "df = pd.read_csv('RESULT_FILES/trainingData.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The file is read using the pandas library and it is stored in the df\n",
    "*dataframe* variable.\n",
    "<p> We can now inspect the database by accessing the first few rows\n",
    "of the file with their index, using the *.iloc[ ]* function, and\n",
    "by printing them on the screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AoA      CL       CD  camber  camber_loc  thickness     Re\n",
      "0 -2.0 -0.1551  0.01968       1           1          6  50000\n",
      "1  0.0  0.0572  0.01435       1           1          6  50000\n",
      "2  2.0  0.2316  0.01576       1           1          6  50000\n",
      "3  4.0  0.5433  0.01971       1           1          6  50000\n"
     ]
    }
   ],
   "source": [
    "#On screen print of the first four rows of the database\n",
    "print(df.iloc[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The database for this tutorial was formerly cleaned of all the\n",
    "non-relevant columns. We can inspect the available features\n",
    "through the built-in pandas feature *df.columns*.\n",
    "<p>We can print them on the screen by simply iterating all over them:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AoA\n",
      "CL\n",
      "CD\n",
      "camber\n",
      "camber_loc\n",
      "thickness\n",
      "Re\n"
     ]
    }
   ],
   "source": [
    "#On screen print of the database columns\n",
    "for cname in df.columns:\n",
    "    print(cname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As previously introduced in the first part of the tutorial, neural networks may be impaired by training data with features having different scales of magnitude and outliers.\n",
    "<br>In general, data regularization/standardization is often beneficial for the neural netwrk training. <br>\n",
    "Here we scale data according to one of the simplest criterion, called\n",
    " *minMax scaler*, that regularize features by bounding all the features between 0 and 1: <br><center>\n",
    " $\\hat{x}=\\frac{x-{x}_{min}}{x_{max}-{x}_{min}}$\n",
    " </center>\n",
    " where:\n",
    " - $\\hat{x}$ is the normalized feature vector\n",
    " - $x$ is the dimensional feature vecotr\n",
    " - $min$ and $max$ are the minimum and the maximum of the feature vector respectively\n",
    " To do so, we can use a for loop to scroll through the columns (features), iteratively computing the minimum and the maximum and eventually normalize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Minmax normalization\n",
    "for cname in df.columns:\n",
    "    df[cname] = (df[cname]-df[cname].min())/(df[cname].max()-df[cname].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now inspect the normalized dataset statistics using the pandas built-in function *pd.describe()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               AoA           CL           CD       camber   camber_loc  \\\n",
      "count  2276.000000  2276.000000  2276.000000  2276.000000  2276.000000   \n",
      "mean      0.488967     0.493499     0.203944     0.479350     0.521383   \n",
      "std       0.318187     0.206408     0.239350     0.371136     0.367524   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.222222     0.354608     0.053910     0.000000     0.333333   \n",
      "50%       0.444444     0.519807     0.096755     0.333333     0.666667   \n",
      "75%       0.777778     0.633627     0.233039     0.666667     1.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "         thickness           Re  \n",
      "count  2276.000000  2276.000000  \n",
      "mean      0.528705     0.289127  \n",
      "std       0.367556     0.388650  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.333333     0.000000  \n",
      "50%       0.666667     0.052632  \n",
      "75%       1.000000     0.210526  \n",
      "max       1.000000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Computes basic statistics of the normalized data and print that on the screen \n",
    "stats = df.describe()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the distribution of data using box plots,\n",
    "that show data distribution with their quantile. <br>\n",
    "We can use the build-in pandas function called *boxplot()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generates a new figure\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "#Box plot using pandas \n",
    "df.boxplot()\n",
    "\n",
    "#Add labels to the axes\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Numerical value')\n",
    "\n",
    "#Show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also visualize the different moments to have an easier\n",
    "inspection of the normalization outcome. Despite being possible\n",
    "to plot data directly with pandas, we will here use the standard\n",
    "Python module for visualization, *matplotlib*, that we previously\n",
    "imported as *plt*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generates a new figure and plots mean/min/max/std for each feature.\n",
    "plt.figure(figsize = (9,9))\n",
    "\n",
    "#Plot mean\n",
    "plt.plot(stats.columns, stats.loc['mean'], c='r', label='mean')\n",
    "\n",
    "#Plot minimum\n",
    "plt.plot(stats.columns, stats.loc['min'], c='b', label='min')\n",
    "\n",
    "#Plot maximum\n",
    "plt.plot(stats.columns, stats.loc['max'], c='g', label='max')\n",
    "\n",
    "#Plot standard deviation\n",
    "plt.plot(stats.columns, stats.loc['std'], c='y', label='std')\n",
    "\n",
    "#Add a legend and a grid \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "#Shows figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After the regularization, the features are limited between 0 and 1.\n",
    "<br> The subsequent step is to divide data between the *train* and\n",
    "*test* subsets. To do so, we use another library, called\n",
    "*scikit-learn*, and its method *train_test_split*. <br>\n",
    "In addition, this utility automatically splits the existing features\n",
    "between **input** or **output**.\n",
    "<br> The database that we are using is already ordered to have the\n",
    "last two columns that correspond to the output. <br>\n",
    "The *train_test_split* function requires as arguments the input and\n",
    "output features and the relative sizes of the two splits. <br>\n",
    "Depending on the application, the training/test size ratio may change,\n",
    "however we use 70% of the dataset as training subsample and 30%\n",
    "as testing subsample, that includes 2276 entires. <br>\n",
    "This function returns four arguments:\n",
    "* **X_train**: training input features, with shape (1594, 5)\n",
    "* **y_train**: training output features, with shape (1594, 2)\n",
    "* **X_test**: testing input features, with shape (682, 5)\n",
    "* **y_test**: testing output features, with shape (682, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Import of the sklearn train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Definition of the input/output features \n",
    "df_shape = df.shape\n",
    "input_features = df[['AoA', 'camber', 'camber_loc', 'thickness', 'Re']]\n",
    "output_features = df[['CL','CD']]\n",
    "\n",
    "#Split in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_features, output_features, test_size=0.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Training a basic model</center></h1>\n",
    "We are now ready to define the neural network architecture. Several deep learning APIs are available for free, <i> e.g.\n",
    "Tensorflow, Keras, Pytorch</i>. In this tutorial we will be using Keras API.\n",
    "Several neural network topologies may compete in solving the same kind of problem, and it is not always easy to\n",
    "determine the best solutions a priori. In this case, we will solve this simple problem by using one of the simplest\n",
    "topology, a feed-forward multi-layer perceptron neural network. <br> We can start importing the necessary modules from the\n",
    "<i>Keras</i> library, distributed with the <i>tensorflow</i> package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-f088f0e0a358>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#import of the tensorflow library\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#import of the tensorflow library\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finding the best architecture for our neural network is not a trivial task, as it is normally one of the goal of the\n",
    "optimization of the neural network. We can start with a basic non-optimized morphology. We can choose as initial structure a three layer\n",
    "feed forward neural network with 5 neurons per biased layer. The number of neurons per layer may be chosen using a rule of thumb: rounding the number of output plus half of the number of input features.\n",
    "As a first assumption, <br><centering> $n_\\text{neur}=f_\\text{out}+0.5*f_\\text{in}=2+0.5*5 \\simeq 5$ </centering><br>\n",
    "We can also draw a fast sketch of the structure to understand data flow across the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the actual structure of the neural network:\n",
    "    ![title](img/nn.svg)\n",
    "<centering> \n",
    "    *Image generated using NN SVG (http://alexlenail.me/NN-SVG/index.html)*\n",
    "</centering>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the first instruction defines an input layer that has 5 neurons that are activated using a Rectified\n",
    "Linear Unit, whereas in the second instruction it is not necessary to specify the shape, as it is automatically derived\n",
    "from the previous layer. In such structure, the first and the second sets of weights have a shape of $f_\\text{in} \\times 5$\n",
    "and $5 \\times 5$ respectively. In our network structure we still miss the output layer with two neurons, corresponding to the number of output features $f_\\text{out}$. Moreover, we no longer want the output to be binded by the ReLU function, therefore we will use a simple linear activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the mathematical formulation underlying neural networks may be complex and time consuming. Luckily, most of the\n",
    "deep-learning APIs like Keras distribute functions that dramatically speed up the process. We can start by defining our simple model through a user-defined function, here called *basic_model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Computes the shape of the input features \n",
    "M,N_feat = X_train.shape\n",
    "\n",
    "# Definition the basic_model function\n",
    "def basic_model():\n",
    "    \n",
    "    #Definition the feed-forward neural network structure\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #Definition of the first hidden layer\n",
    "    model.add(keras.layers.Dense(5, input_dim=N_feat, activation='tanh'))\n",
    "    \n",
    "    #Definition of the second hidden layer\n",
    "    model.add(keras.layers.Dense(5, activation='tanh'))\n",
    "    \n",
    "    #Definition of the output layer\n",
    "    model.add(keras.layers.Dense(2, activation='linear'))\n",
    "    \n",
    "    #Definition of the optimizer \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    \n",
    "    #Definition of the cost function\n",
    "    cost = keras.losses.MeanSquaredError()\n",
    "    \n",
    "    #Model finalization\n",
    "    model.compile(optimizer=opt,loss=cost)\n",
    "    \n",
    "    #Model return\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the last three lines of the function definition we are coding three relevant aspect of the neural network:\n",
    "<ul>\n",
    "<li>the learning rate (0.01)</li>\n",
    "<li>the cost function (Mean squared error)</li>\n",
    "<li>the optimizer (Adam)</li>\n",
    "</ul>\n",
    "<br> \n",
    "Even if Adam optimizer adapts the learning rate during the training phase, it has an impact on the speed of the algorithm. In fact, it controls the proportion that weights are updated. Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5) slow learning right down during training. <br>\n",
    "The choice of the cost function (also called loss function), depends mainly on the task to solve(regression\\classification). Its role in the neural network process is to determine the cost, i.e. the error that we are making between prediction and true values. As the gradients of losses are computed based on the cost function, it strongly affects the proper convergence of the optimizer. In this case we will use a common expression, the Mean Squared Error (MSE) function, defined as: <br><center>\n",
    "    $\\text{MSE}= \\frac{\\sum_{t=1}^T \\left(\\hat{y}_1-y\\right)^2}{T}$\n",
    "    </center><br>\n",
    "    \n",
    "The optimizer defines how to change weights or learning rates of the neural network to reduce the losses we previously defined. Adam optimizer has gained the favour of the community thanks to its fast convergence and adaptive learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now everything is set up to start the training of the neural network. To do so, we use the *fit* command. The fit method accepts several arguments that may help or impair the convergence of the model. We want to specify that we want to use X_train and y_train as input/output of the training of the model and that X_test and y_test must be used to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Model training\n",
    "history = basic_model().fit(X_train, y_train, epochs=200, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training and test losses, i.e. the computed MSE, are stored in the *history* variable. The history variable belongs to the *dictionary* type. Dictionaries are Python data structures that can be indexed using their *keys*, inspectable using the *.keys()* command.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#On screen print of the history dictionary\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to plot both of them in the same figure, to compare the convergence hisotry and enstablish if the model is overfitting or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a new figure\n",
    "plt.figure()\n",
    "#Plotter of the training and test MSE\n",
    "plt.plot(history.history['loss'], c='k',label='Train')\n",
    "plt.plot(history.history['val_loss'], c='r', label = 'Test', ls='--')\n",
    "#Shows legend and add labels to the plot\n",
    "plt.legend()\n",
    "plt.xlabel('Nr. of Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As both series (train and test MSE) are converging, we can assess that the model is behaving correctly in both datasets. Such visualization, however, provides a broad view on the model, without additional information on the local behavior of the model. For example, our artificial intelligence may work correctly within a certain range of the input features while underfitting in the rest of data. As MSE is averaged over the observations, we may not notice such problem and end up with an ill-conditioned model. We can generate a simple plot that compares the predicted output versus the true values for each of the outputs of the model. Let's start with the training data.<br>\n",
    "We first want to store the predictions of the model for both train and test data in the *y_train_pred* and *y_test_pred* variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Computes predictions of the model for both train and test datasets\n",
    "y_train_pred = basic_model().predict(X_train)\n",
    "y_test_pred = basic_model().predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now compare them and see how the model is performing locally. An immediate way is to plot the true outputs of the model on both axes of a graph. In so doing, reference data is represented as a line. The output of the model is instead represented using the true output of the model on one of the axis and the predicted values on the other axis. The error of the model can therefore be visualized as the distance between the predicted points and the solid line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a new figure with two subplots\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "#Cl plot with a 1:1 aspect ratio\n",
    "ax1 = fig.add_subplot(1,2,1, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax1.plot(y_train.values[:,0],y_train.values[:,0], c='k')\n",
    "#Plot model output as black empty circles\n",
    "ax1.scatter(y_train.values[:,0], y_train_pred[:,0], facecolor = 'none', edgecolor='k')\n",
    "#Add title and axes labels\n",
    "ax1.set_title('Cl - Train')\n",
    "ax1.set_xlabel('y_train')\n",
    "ax1.set_ylabel('y_train / y_train_pred')\n",
    "\n",
    "#Cd plot with a 1:1 aspect ratio\n",
    "ax2 = fig.add_subplot(1,2,2, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax2.plot(y_train.values[:,1],y_train.values[:,1], c='k', label='True')\n",
    "#Plot model output as black empty circles\n",
    "ax2.scatter(y_train.values[:,1], y_train_pred[:,1], facecolor = 'none', edgecolor='k', label='Predicted')\n",
    "#Add title and axes labels and a legend\n",
    "ax2.legend()\n",
    "ax2.set_title('Cd - Train')\n",
    "ax2.set_xlabel('y_train')\n",
    "ax2.set_ylabel('y_train / y_train_pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can adapt the same lines of code for the test database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a new figure with two subplots\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "#Cl plot with a 1:1 aspect ratio\n",
    "ax1 = fig.add_subplot(1,2,1, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax1.plot(y_test.values[:,0],y_test.values[:,0], c='k')\n",
    "#Plot model output as black empty circles\n",
    "ax1.scatter(y_test.values[:,0], y_test_pred[:,0], facecolor = 'none', edgecolor='k')\n",
    "#Add title and axes labels\n",
    "ax1.set_title('Cl - Test')\n",
    "ax1.set_xlabel('y_test')\n",
    "ax1.set_ylabel('y_test / y_test_pred')\n",
    "\n",
    "#Cd plot with a 1:1 aspect ratio\n",
    "ax2 = fig.add_subplot(1,2,2, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax2.plot(y_test.values[:,1],y_test.values[:,1], c='k', label='True')\n",
    "#Plot model output as black empty circles\n",
    "ax2.scatter(y_test.values[:,1], y_test_pred[:,1], facecolor = 'none', edgecolor='k', label='Predicted')\n",
    "#Add title and axes labels and a legend\n",
    "ax2.legend()\n",
    "ax2.set_title('Cd - Test')\n",
    "ax2.set_xlabel('y_test')\n",
    "ax2.set_ylabel('y_test / y_test_pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is evident that the errors are large and the trained model is useless as it is. The initial selection selection of the hyperparameters of the neural network is not suited to solve this particular task. It is now time to optimize the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Optimizing the model</center></h1>\n",
    "The optimization phase of the alogrithm is usually a computationally expensive and tedious process. The aim is to find the best combinations of hyperamters to achieve the highest accuracy / least error while making prediction. Depending on the computational costs of the training, we can investigate from tens to thousands possible combination of several hyperparameters and their effect on the neural network. In the simplest optimization, we can manually choose some combinations and hard-code them in the algorithm. However, this non-automatic approach is simply unfeasible for complex architectures. We will hereby use an hyperparameter optimizer already distributed in Keras, called *Keras Tuner*. We will define a search space and find out the best combination of hyperparameters. \n",
    "Our goal here is to find the best combination of:\n",
    "\n",
    "- **number of neurons**, ranging from 4 to 32\n",
    "- **activation functions**, choosing beetween ReLu and tanh\n",
    "- **learning rate**, choosing between 1e-2, 1e-3, 1e-4\n",
    "\n",
    "The first step is to define a dynamic structure of the neural network. In this new function, *model_builder*, the input argument *hp* is provided by the Keras Tuner. The number of neurons is a variable called *hp_units*, defined as integer, that varies from 4 to 32 with a 4 stride. The number of neurons is considered constant along all layers. We have also added a *dropout* layer between each hidden layer to increase the robustness of the model to overfitting. This layer randomly sets input units to 0 with a 30 % frequency of rate at each step during training time. The different acivations are chosen using the function *hp.Choice*, where we specify the availabe options. The same goes for the learning rate, stored in the *hp_learning_rate* variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_builder(hp):\n",
    "    #Definition the feed-forward neural network structure\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    #Declares the number of neurons to optimize\n",
    "    hp_units = hp.Int('units', min_value=4, max_value=68, step=8)\n",
    "    \n",
    "    #Chooses between relu and tanh for the first layer\n",
    "    act1 = hp.Choice('act1', values=['relu', 'tanh'])\n",
    "    \n",
    "    #Definition of the first hidden layer\n",
    "    model.add(keras.layers.Dense(hp_units, input_dim=N_feat, activation=act1))\n",
    "    \n",
    "    #Adds a dropout layer = 30%\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    #Chooses between relu and tanh for the second layer\n",
    "    act2 = hp.Choice('act2', values=['relu', 'tanh'])\n",
    "    \n",
    "    #Adds a dropout layer = 30%\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    #Definition of the second hidden layer\n",
    "    model.add(keras.layers.Dense(hp_units, activation=act2))\n",
    "    \n",
    "    #Adds a dropout layer = 30%\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    #Chooses between relu and tanh for the first layer\n",
    "    act3 = hp.Choice('act3', values=['relu', 'tanh'])\n",
    "    \n",
    "    #Definition of the third hidden layer\n",
    "    model.add(keras.layers.Dense(hp_units, activation=act3))\n",
    "\n",
    "    #Definition of the output layer\n",
    "    model.add(keras.layers.Dense(2, activation='linear'))\n",
    "    \n",
    "    #Chooses between three possible learning rate \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    #Model finalization\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=keras.losses.MeanSquaredError())\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now import the required module for the hyperparameter optimization. Among the possible optimizers, we are here using the *Hyperband* algorithm. To reduce the computational costs of training multiple neural network, we are limited the number of epochs to 100 and the maximum number of executions per trial to 3. The metric that is used to optimize the algorithm is the loss computed on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Import of the required module\n",
    "from kerastuner.tuners import Hyperband\n",
    "\n",
    "#Definition of the tuner\n",
    "tuner = Hyperband(\n",
    "    model_builder,\n",
    "    max_epochs=100,\n",
    "    objective='val_loss',\n",
    "    seed=111,\n",
    "    executions_per_trial=3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Everything is now set up to run the optimization process. Please notice that the following expression is the same as the *.fit()* function that we previously used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Start the hyperband search algoirthm\n",
    "tuner.search(X_train, y_train, epochs=30, validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After the optimization is finished, we can get the best model with the corresponding hyperparameters by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Gets the best combination of hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "#Gets the best model \n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is also possible to have a summary of the optimization results by simply running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Prints a summary of the results of the hyperband optimization\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now evaluate the performace of the algorithm. The process is exactly the same, we evaluate the convergence of the algorithm, then the output of the model for both training and test datasets. In this case, we don't want to stop the training of the algorithm too early. In so doing, in fact, we could obtain a suboptimal combination of weight and biases. We want to set the number of trainig epochs to a large number and then code a stopping criterion to interrupt the training when certain conditions are met. This is also called *early stopping*. To do so, we can use a *callback* function already implemented in Keras. In particular, the following command stops the training when the test loss is not improved during five subsequent epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Early stopping criterion definition\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=30, \n",
    "                                         min_delta=0.0001,mode='auto')\n",
    "\n",
    "#Optimized model training\n",
    "history = best_model.fit(X_train, y_train, epochs=2000, callbacks=[callback],\n",
    "                         validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now plot the convergence history as we did previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a new figure\n",
    "plt.figure()\n",
    "#Plotter of the training and test MSE\n",
    "plt.plot(history.history['loss'], c='k',label='Train')\n",
    "plt.plot(history.history['val_loss'], c='r', label = 'Test', ls='--')\n",
    "#Shows legend and add labels to the plot\n",
    "plt.legend()\n",
    "plt.xlabel('Nr. of Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We first derive the prediction for the train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Stores the output of the trained model\n",
    "y_train_pred = best_model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Creates a new figure with two subplots\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "#Cl plot with a 1:1 aspect ratio\n",
    "ax1 = fig.add_subplot(1,2,1, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax1.plot(y_train.values[:,0],y_train.values[:,0], c='k')\n",
    "#Plot model output as black empty circles\n",
    "ax1.scatter(y_train.values[:,0], y_train_pred[:,0], facecolor = 'none', edgecolor='k')\n",
    "#Add title and axes labels\n",
    "ax1.set_title('Cl - Train')\n",
    "ax1.set_xlabel('y_train')\n",
    "ax1.set_ylabel('y_train / y_train_pred')\n",
    "\n",
    "#Cd plot with a 1:1 aspect ratio\n",
    "ax2 = fig.add_subplot(1,2,2, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax2.plot(y_train.values[:,1],y_train.values[:,1], c='k', label='True')\n",
    "#Plot model output as black empty circles\n",
    "ax2.scatter(y_train.values[:,1], y_train_pred[:,1], facecolor = 'none', edgecolor='k', label='Predicted')\n",
    "#Add title and axes labels and a legend\n",
    "ax2.legend()\n",
    "ax2.set_title('Cd - Train')\n",
    "ax2.set_xlabel('y_train')\n",
    "ax2.set_ylabel('y_train / y_train_pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now do the same for the test database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluates the output of the model on the test data \n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "#Creates a new figure with two subplots\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "#Cl plot with a 1:1 aspect ratio\n",
    "ax1 = fig.add_subplot(1,2,1, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax1.plot(y_test.values[:,0],y_test.values[:,0], c='k')\n",
    "#Plot model output as black empty circles\n",
    "ax1.scatter(y_test.values[:,0], y_test_pred[:,0], facecolor = 'none', edgecolor='k')\n",
    "#Add title and axes labels\n",
    "ax1.set_title('Cl - Test')\n",
    "ax1.set_xlabel('y_test')\n",
    "ax1.set_ylabel('y_test / y_test_pred')\n",
    "\n",
    "#Cd plot with a 1:1 aspect ratio\n",
    "ax2 = fig.add_subplot(1,2,2, adjustable='box', aspect=1)\n",
    "#Plot reference data as a solid black line\n",
    "ax2.plot(y_test.values[:,1],y_test.values[:,1], c='k', label='True')\n",
    "#Plot model output as black empty circles\n",
    "ax2.scatter(y_test.values[:,1], y_test_pred[:,1], facecolor = 'none', edgecolor='k', label='Predicted')\n",
    "#Add title and axes labels and a legend\n",
    "ax2.legend()\n",
    "ax2.set_title('Cd - Test')\n",
    "ax2.set_xlabel('y_test')\n",
    "ax2.set_ylabel('y_test / y_test_pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "PyCharm (Sistemi Energetici 2019-20)",
   "language": "python",
   "name": "pycharm-4d013c7a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}